{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from DCGan import *\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import *\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class DCDiscriminator(nn.Module):\n",
    "    def __init__(self, img_size:int=32, channels:int=1):\n",
    "        super().__init__()\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.adv_layer(x)\n",
    "        return x\n",
    "    \n",
    "class DCGenerator(nn.Module):\n",
    "    def __init__(self, img_size:int=32, latent_dim:int=100, channels:int=1):\n",
    "        super().__init__()\n",
    "        self.init_size = img_size // 4\n",
    "        self.L1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.L1(x)\n",
    "        x = x.view(x.shape[0], 128, self.init_size, self.init_size)\n",
    "        x = self.conv_blocks(x)\n",
    "        return x\n",
    "    \n",
    "class NewGenerator(nn.Module):\n",
    "    def __init__(self, \n",
    "                 latent:int=100, #size latent vector z\n",
    "                 ngf:int=64, #size of feature map in generator\n",
    "                 nc:int=3 #num channell img\n",
    "                 ) -> None:       \n",
    "        super().__init__()\n",
    "        self.model_generator = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.model_generator(X)\n",
    "\n",
    "class NewDiscriminator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 nc:int=3, #num channell img\n",
    "                 ndf:int=64 #size of feature map in discriminator\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        self.model_discriminator = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "           \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return \n",
    "\n",
    "def normal_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(model.bias.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewGenerator(\n",
       "  (model_generator): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = NewGenerator()\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCGenerator(\n",
       "  (L1): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=8192, bias=True)\n",
       "  )\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen1 = DCGenerator()\n",
    "gen1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alfa:\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.a = kwargs.get(\"a\")\n",
    "        print(self.a)\n",
    "    def train(self):\n",
    "        for j in range(1):\n",
    "            for i, _ in enumerate((pbar := tqdm(self.a))):\n",
    "                print(i, _)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "p = Alfa(a=list(range(100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "fixed_noise = torch.randn(64, latent, 1, 1, device=device)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = discriminator(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = Loss(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = discriminator(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = Loss(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Return an enumerate object.\n",
      "\n",
      "  iterable\n",
      "    an object supporting iteration\n",
      "\n",
      "The enumerate object yields pairs containing a count (from start, which\n",
      "defaults to zero) and a value yielded by the iterable argument.\n",
      "\n",
      "enumerate is useful for obtaining an indexed list:\n",
      "    (0, seq[0]), (1, seq[1]), (2, seq[2]), ...\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "?enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 99888.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      "28 28\n",
      "29 29\n",
      "30 30\n",
      "31 31\n",
      "32 32\n",
      "33 33\n",
      "34 34\n",
      "35 35\n",
      "36 36\n",
      "37 37\n",
      "38 38\n",
      "39 39\n",
      "40 40\n",
      "41 41\n",
      "42 42\n",
      "43 43\n",
      "44 44\n",
      "45 45\n",
      "46 46\n",
      "47 47\n",
      "48 48\n",
      "49 49\n",
      "50 50\n",
      "51 51\n",
      "52 52\n",
      "53 53\n",
      "54 54\n",
      "55 55\n",
      "56 56\n",
      "57 57\n",
      "58 58\n",
      "59 59\n",
      "60 60\n",
      "61 61\n",
      "62 62\n",
      "63 63\n",
      "64 64\n",
      "65 65\n",
      "66 66\n",
      "67 67\n",
      "68 68\n",
      "69 69\n",
      "70 70\n",
      "71 71\n",
      "72 72\n",
      "73 73\n",
      "74 74\n",
      "75 75\n",
      "76 76\n",
      "77 77\n",
      "78 78\n",
      "79 79\n",
      "80 80\n",
      "81 81\n",
      "82 82\n",
      "83 83\n",
      "84 84\n",
      "85 85\n",
      "86 86\n",
      "87 87\n",
      "88 88\n",
      "89 89\n",
      "90 90\n",
      "91 91\n",
      "92 92\n",
      "93 93\n",
      "94 94\n",
      "95 95\n",
      "96 96\n",
      "97 97\n",
      "98 98\n",
      "99 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: empty expression not allowed (4088723116.py, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [52]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pbar.set(f\"{}\\t{}\")\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: empty expression not allowed\n"
     ]
    }
   ],
   "source": [
    "class  DCGanTrainer():\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.img_size = kwargs.get(\"img_size\")\n",
    "        #self.dataloader = kwargs.get(\"dataloader\")\n",
    "        self.discriminator = kwargs.get(\"discriminator\")\n",
    "        self.generator = kwargs.get(\"generator\")\n",
    "        ngpu = kwargs.get(\"ngpu\")\n",
    "        self.lr = kwargs.get(\"lr\")\n",
    "        self.betas = kwargs.get(\"betas\") #tuple: (0.5, 0.999)\n",
    "        self.batch_size = kwargs.get(\"batch_size\")\n",
    "        self.latent_dim = kwargs.get(\"latent_dim\")\n",
    "        self.epochs = kwargs.get(\"epochs\")\n",
    "        self.optim = kwargs.get(\"optimizer\")\n",
    "        self.Loss = kwargs.get(\"loss\")\n",
    "        self.Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "        self.vid = kwargs.get(\"video\")\n",
    "        seed = kwargs.get(\"seed\")\n",
    "        self.nworker = kwargs.get(\"nworker\")\n",
    "        self.path2data = kwargs.get(\"path_to_data\")\n",
    "        if self.vid:\n",
    "            self.VideoGenerator = VideoGenerator(size=(self.img_size, self.img_size))\n",
    "        \n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            torch.manual_seed(seed=seed)\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.discriminator.to(self.device)\n",
    "        self.generator.to(self.device)\n",
    "\n",
    "        def parallel(model):\n",
    "            model = nn.DataParallel(model, list(range(ngpu)))\n",
    "\n",
    "        def create_dataloader(self, path_dataset:str, nworker:int=1, batch_size:int=128, img_size:int=32):\n",
    "                    dataset = datasets.ImageFolder(root=path_dataset, \n",
    "                                                transform=transforms.Compose([\n",
    "                                                    transforms.Resize(img_size),\n",
    "                                                    transforms.CenterCrop(img_size),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                                ]))\n",
    "                    return torch.utils.data.DataLoader(dataset, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    shuffle=True,\n",
    "                                                    num_workers=nworker)\n",
    "        if kwargs.get(\"parallel\"):\n",
    "            parallel(self.discriminator)\n",
    "            parallel(self.generator)\n",
    "\n",
    "        self.generator.apply(normal_weights)\n",
    "        self.discriminator.apply(normal_weights)\n",
    "\n",
    "        self.optimizer_G = self.optim(self.generator.parameters(), lr=self.lr, betas=self.betas)\n",
    "        self.optimizer_D = self.optim(self.discriminator.parameters(), lr=self.lr, betas=self.betas)\n",
    "        \n",
    "        self.dataloader = create_dataloader(self.path2data, self.nworker, self.batch_size, self.img_size)\n",
    "    def train(self):\n",
    "        f=0\n",
    "        for epoch in range(self.epochs):\n",
    "            for i, (imgs, _) in enumerate((pbar := tqdm(self.dataloader))):\n",
    "\n",
    "            \n",
    "                valid = Variable(self.Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "                fake = Variable(self.Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "                \n",
    "                real_imgs = Variable(imgs.type(self.Tensor))\n",
    "                self.optimizer_G.zero_grad()\n",
    "\n",
    "            \n",
    "                z = Variable(self.Tensor(np.random.normal(0, 1, (imgs.shape[0], self.latent_dim))))\n",
    "\n",
    "            \n",
    "                gen_imgs = self.generator(z)\n",
    "\n",
    "                g_loss = self.Loss(self.discriminator(gen_imgs), valid)\n",
    "\n",
    "                g_loss.backward()\n",
    "                self.optimizer_G.step()\n",
    "\n",
    "            \n",
    "                self.optimizer_D.zero_grad()\n",
    "\n",
    "                real_loss = self.Loss(self.discriminator(real_imgs), valid)\n",
    "                fake_loss = self.Loss(self.discriminator(gen_imgs.detach()), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "                d_loss.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                #print(\n",
    "                #    \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                #    % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "                #)\n",
    "        \n",
    "                if self.vid:\n",
    "                    self.VideoGenerator.add_image(make_grid(gen_imgs, padding=2, normalize=True))\n",
    "                else:\n",
    "                    save_image(gen_imgs.data[:25], f\"images/{f}.png\", nrow=5, normalize=True)\n",
    "                    f+=1\n",
    "                pbar.set_description(f\"LossG {g_loss.item()}\\tLossD {d_loss.item()}\")\n",
    "                \n",
    "    def train_new(self):\n",
    "        self.img_list = []\n",
    "        G_losses = []\n",
    "        D_losses = []\n",
    "        iters = 0\n",
    "        real_label = 1.\n",
    "        fake_label = 0.\n",
    "        fixed_noise = torch.randn(64, self.latent_dim, 1, 1, device=self.device)\n",
    "        for epoch in range(self.epochs):\n",
    "            for i, data in enumerate(self.dataloader):\n",
    "\n",
    "                self.discriminator.zero_grad()\n",
    "                # Format batch\n",
    "                real_cpu = data[0].to(self.device)\n",
    "                b_size = real_cpu.size(0)\n",
    "                label = torch.full((b_size,), real_label, dtype=torch.float, device=self.device)\n",
    "                # Forward pass real batch through D\n",
    "                output = self.discriminator(real_cpu).view(-1)\n",
    "                # Calculate loss on all-real batch\n",
    "                errD_real = self.Loss(output, label)\n",
    "                # Calculate gradients for D in backward pass\n",
    "                errD_real.backward()\n",
    "                D_x = output.mean().item()\n",
    "\n",
    "                ## Train with all-fake batch\n",
    "                # Generate batch of latent vectors\n",
    "                noise = torch.randn(b_size, self.latent_dim, 1, 1, device=self.device)\n",
    "                # Generate fake image batch with G\n",
    "                fake = self.discriminator(noise)\n",
    "                label.fill_(fake_label)\n",
    "                # Classify all fake batch with D\n",
    "                output = self.discriminator(fake.detach()).view(-1)\n",
    "                # Calculate D's loss on the all-fake batch\n",
    "                errD_fake = self.Loss(output, label)\n",
    "                # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "                errD_fake.backward()\n",
    "                D_G_z1 = output.mean().item()\n",
    "                # Compute error of D as sum over the fake and the real batches\n",
    "                errD = errD_real + errD_fake\n",
    "                # Update D\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                ############################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                ###########################\n",
    "                self.generator.zero_grad()\n",
    "                label.fill_(real_label)  # fake labels are real for generator cost\n",
    "                # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "                output = self.discriminator(fake).view(-1)\n",
    "                # Calculate G's loss based on this output\n",
    "                errG = self.Loss(output, label)\n",
    "                # Calculate gradients for G\n",
    "                errG.backward()\n",
    "                D_G_z2 = output.mean().item()\n",
    "                # Update G\n",
    "                self.optimizer_G.step()\n",
    "\n",
    "                if i % 50 == 0:\n",
    "                    print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                        % (epoch, self.epochs, i, len(self.dataloader),\n",
    "                            errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "                G_losses.append(errG.item())\n",
    "                D_losses.append(errD.item())\n",
    "\n",
    "                if (iters % 500 == 0) or ((epoch == self.epochs-1) and (i == len(self.dataloader)-1)):\n",
    "                    with torch.no_grad():\n",
    "                        fake = self.generator(fixed_noise).detach().cpu()\n",
    "                    self.img_list.append(make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "                iters += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGenerator:\n",
    "    def __init__(self, size: tuple = (256, 256), result_path:str=\"./video\", format_out:str=\"MP4V\", n_second:int=None):\n",
    "        self.Images = list()\n",
    "        self.format = format_out\n",
    "        self.n_second = n_second\n",
    "        self.path = result_path\n",
    "    def add_image(self, image):\n",
    "        self.Images.append(image)\n",
    "        \n",
    "    def generate_video(self):\n",
    "        if self.n_second is None:\n",
    "            fps = 1\n",
    "        else:\n",
    "            fps = len(self.Images)//self.n_second\n",
    "        name = \"gan_traine/\"\n",
    "        path = os.path.join(self.path, name)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        vid = cv2.VideoCapture(path)\n",
    "        #vid_name = os.path.basename(video)\n",
    "        #total = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        #fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "        #w = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        #h = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        codec = cv2.VideoWriter_fourcc(*self.format)\n",
    "        out = cv2.VideoWriter(f'{path}GAN.mp4',codec , fps, self.size)\n",
    "        for img in self.Images:\n",
    "            out.write(img)\n",
    "        out.release()\n",
    "    def plt_animate(self, in_notebook:bool=False):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        ims = [[plt.imshow(np.transpose(i, (1,2,0)), animated=True)] for i in self.Images]        \n",
    "        ani =  anim.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "        if in_notebook:\n",
    "            HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = DCGanTrainer(img_size=32, \n",
    "                       dataloader=None, \n",
    "                       discriminator=DCDiscriminator(), \n",
    "                       generator=DCGenerator(), \n",
    "                       ngpu=0, \n",
    "                       parallel=False, \n",
    "                       optimizer=torch.optim.Adam, \n",
    "                       betas=(0.5, 0.999), \n",
    "                       batch_size=200,\n",
    "                       lr=2e-4,\n",
    "                       epochs=10,\n",
    "                       latent_dim=100,\n",
    "                       loss=nn.BCELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.5, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0002\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainer.optimizer_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8//3 == int(8/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2000 % 1909"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67783390838d2e02912aac04d405c75735cc05868bfeaabbe6ec2bbdb2e2542d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
